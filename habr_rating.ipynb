{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mean_vectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(next(iter(w2v.values())))\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec.get(w, np.zeros(self.dim)) for w in words], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('rating/train_content.csv', parse_dates=['date'])\n",
    "test_df = pd.read_csv('rating/test_content.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/yulits/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stops = set(stopwords.words('english')) | set(stopwords.words('russian'))\n",
    "\n",
    "def review_to_wordlist(review):\n",
    "    review_text = re.sub(\"^A-Za-zА-Яа-я\", \" \", review)\n",
    "    words = review_text.lower().split()\n",
    "    words = [w for w in words if not w in stops]\n",
    "    words = [morph.parse(w)[0].normal_form for w in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['year'] = train_df['date'].apply(lambda x: x.year)\n",
    "train_df['month'] = train_df['date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23425, 15), (7556, 15), 3.4046228249071526, 3.304679829935242)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df[train_df['year'] == 2015]\n",
    "X_val = train_df[(train_df['year'] == 2016) & (train_df['month'] <= 4)]\n",
    "y_train = X_train['favs_lognorm']\n",
    "y_val = X_val['favs_lognorm']\n",
    "X_train.shape, X_val.shape, y_train.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_train, X_val], axis=0,  ignore_index=True)\n",
    "data['content_clear'] = data['content'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 27s, sys: 1.55 s, total: 45min 29s\n",
      "Wall time: 45min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['content_clear'] = data['content_clear'].apply(review_to_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('content_clear.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('content_clear.pickle', 'rb') as f:\n",
    "    data = \n",
    "\n",
    "data['content'][0]\n",
    "pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<img',\n",
       " 'src=\"https://habrastorage.org/files/50e/211/9a0/50e2119a0508439ba77d8eb2dc2234ce.jpg\"',\n",
       " 'alt=\"pricing\"',\n",
       " 'align=\"left\">большинство',\n",
       " 'предприниматель',\n",
       " 'сосредотачиваться',\n",
       " 'создание',\n",
       " 'инновационный',\n",
       " 'продукта,',\n",
       " 'забывают,',\n",
       " 'элегантный',\n",
       " 'решение',\n",
       " 'автоматически',\n",
       " 'превращаться',\n",
       " 'успешный',\n",
       " 'бизнес.',\n",
       " 'компания',\n",
       " 'требоваться',\n",
       " 'столь',\n",
       " 'элегантный',\n",
       " 'бизнес-модель,',\n",
       " 'правильный',\n",
       " 'ценовый',\n",
       " 'политикой,',\n",
       " 'канал',\n",
       " 'сбыт',\n",
       " 'взаимоотношение',\n",
       " 'клиентами.<br>',\n",
       " '<br>',\n",
       " 'поиск',\n",
       " 'правильный',\n",
       " 'бизнес-модель',\n",
       " 'требовать',\n",
       " 'такой',\n",
       " 'усердия,',\n",
       " 'проектирование',\n",
       " 'правильный',\n",
       " 'продукта,',\n",
       " 'подход',\n",
       " 'требовать',\n",
       " 'навык',\n",
       " 'отличаются.',\n",
       " 'поэтому',\n",
       " 'инвестор',\n",
       " 'признают,',\n",
       " 'соучредитель',\n",
       " 'лучше,',\n",
       " 'один.',\n",
       " 'время',\n",
       " 'сосредоточиться',\n",
       " 'разработка',\n",
       " 'продукта,',\n",
       " 'два',\n",
       " 'сделать',\n",
       " 'упор',\n",
       " 'поиск',\n",
       " 'разработка',\n",
       " 'бизнес-модели.',\n",
       " 'оба',\n",
       " 'аспект',\n",
       " 'должный',\n",
       " 'выполняться',\n",
       " 'параллельно.<br>',\n",
       " '<br>',\n",
       " 'управленческий',\n",
       " 'тандем',\n",
       " 'взглянуть',\n",
       " 'бизнес',\n",
       " 'разный',\n",
       " 'сторон,',\n",
       " 'дальнейший',\n",
       " 'позволить',\n",
       " 'избежать',\n",
       " 'множество',\n",
       " 'проблем.',\n",
       " 'учредитель',\n",
       " 'мочь',\n",
       " 'произвести',\n",
       " 'независимый',\n",
       " 'исследование',\n",
       " 'свой',\n",
       " 'сектора.',\n",
       " 'инвестиционный',\n",
       " 'сообществе,',\n",
       " 'подобный',\n",
       " 'работа',\n",
       " 'называться',\n",
       " 'доказательство',\n",
       " 'бизнес-модели.',\n",
       " 'оно',\n",
       " 'начинаться',\n",
       " 'проверка',\n",
       " 'бизнес-возможность',\n",
       " 'модели,',\n",
       " 'многое',\n",
       " 'же,',\n",
       " 'концепция',\n",
       " 'прототип',\n",
       " 'продукт',\n",
       " 'проверять',\n",
       " 'технический',\n",
       " 'решение.<br>',\n",
       " '<br>',\n",
       " 'помощь',\n",
       " 'следующий',\n",
       " 'шаг',\n",
       " 'возможный',\n",
       " 'постройка',\n",
       " 'правильный',\n",
       " 'бизнес-модели:<br>',\n",
       " '<a',\n",
       " 'name=\"habracut\"></a><br>',\n",
       " '<h3>согласование',\n",
       " 'стоимость',\n",
       " 'решение',\n",
       " 'целевой',\n",
       " 'сегменте</h3><br>',\n",
       " 'клиент',\n",
       " 'часто',\n",
       " 'жаловаться',\n",
       " 'отсутствие',\n",
       " 'комплексный',\n",
       " 'интуитивный',\n",
       " 'подхода,',\n",
       " 'вместе',\n",
       " 'привычность',\n",
       " 'предыдущий',\n",
       " 'решений.',\n",
       " 'необходимый',\n",
       " 'правильно',\n",
       " 'оценить',\n",
       " 'стоимость',\n",
       " 'свой',\n",
       " 'продукта.',\n",
       " 'слишком',\n",
       " 'дорогой',\n",
       " 'продукт',\n",
       " 'пользоваться',\n",
       " 'популярностью,',\n",
       " 'слишком',\n",
       " 'дешёвый',\n",
       " '—',\n",
       " 'отпугнуть',\n",
       " 'покупателя.',\n",
       " 'дать',\n",
       " 'ситуация',\n",
       " 'необходимый',\n",
       " 'рассчитать',\n",
       " 'свой',\n",
       " 'цена',\n",
       " 'тот',\n",
       " 'порядках,',\n",
       " 'конкурент',\n",
       " 'сходный',\n",
       " 'качество',\n",
       " 'предоставлять',\n",
       " 'товар',\n",
       " 'услуг.<br>',\n",
       " '<br>',\n",
       " '<h3>проверка',\n",
       " 'действенность',\n",
       " 'продукта</h3><br>',\n",
       " 'предварительный',\n",
       " 'версия',\n",
       " 'продукта,',\n",
       " 'нужно',\n",
       " 'подвергнуть',\n",
       " 'воздействие',\n",
       " 'реальный',\n",
       " 'клиентов,',\n",
       " 'увидеть',\n",
       " 'реакцию.',\n",
       " 'процесс',\n",
       " 'испытание',\n",
       " 'необходимый',\n",
       " 'учитывать',\n",
       " 'обратный',\n",
       " 'связь.',\n",
       " 'реакция',\n",
       " 'неудовлетворительный',\n",
       " 'никакой',\n",
       " 'бизнес-модель',\n",
       " 'спасти',\n",
       " 'краха.<br>',\n",
       " '<br>',\n",
       " '<h3>проверка',\n",
       " 'канал',\n",
       " 'сбыт',\n",
       " 'взаимодействие',\n",
       " 'клиентами</h3><br>',\n",
       " 'выполнять',\n",
       " 'шаг',\n",
       " 'простой',\n",
       " 'помощь',\n",
       " 'фокус',\n",
       " 'группы.',\n",
       " 'это',\n",
       " 'просто',\n",
       " 'презентация',\n",
       " 'продукта.',\n",
       " 'шаг',\n",
       " 'включать',\n",
       " 'элемент',\n",
       " 'ценообразования,',\n",
       " 'маркетинга,',\n",
       " 'распределение',\n",
       " 'обслуживания.',\n",
       " 'процесс',\n",
       " 'исполнение',\n",
       " 'существовать',\n",
       " 'возможность',\n",
       " 'вообще',\n",
       " 'избежать',\n",
       " 'любой',\n",
       " 'затрат.<br>',\n",
       " '<br>',\n",
       " '<h3>консультация',\n",
       " 'эксперт',\n",
       " 'инвесторами</h3><br>',\n",
       " 'небольшой',\n",
       " 'консультативный',\n",
       " 'совет',\n",
       " 'посторонний',\n",
       " 'людей,',\n",
       " 'иметь',\n",
       " 'опыт',\n",
       " 'соответствующий',\n",
       " 'сфера',\n",
       " 'дать',\n",
       " 'объективный',\n",
       " 'обратный',\n",
       " 'связь,',\n",
       " 'необходимый',\n",
       " 'создание',\n",
       " 'канал',\n",
       " 'дистрибуция',\n",
       " 'продаж.',\n",
       " 'данный',\n",
       " 'пункт',\n",
       " 'отношение',\n",
       " 'потенциальный',\n",
       " 'инвестор',\n",
       " 'оказать',\n",
       " 'огромный',\n",
       " 'пользу,',\n",
       " 'начало',\n",
       " 'планироваться',\n",
       " 'задействование.<br>',\n",
       " '<br>',\n",
       " '<h3>планирование',\n",
       " 'исполнение',\n",
       " 'пилотный',\n",
       " 'версия',\n",
       " 'территориальный',\n",
       " 'развертывание</h3><br>',\n",
       " 'оценка',\n",
       " 'traction',\n",
       " 'ограниченный',\n",
       " 'территориальный',\n",
       " 'развёртывание',\n",
       " 'являться',\n",
       " 'отличный',\n",
       " 'проверка',\n",
       " 'бизнес-модели.',\n",
       " 'данный',\n",
       " 'шаг',\n",
       " 'позволить',\n",
       " 'оценить',\n",
       " 'затраты,',\n",
       " 'качество',\n",
       " 'ценообразование',\n",
       " 'несколько',\n",
       " 'точка',\n",
       " 'один',\n",
       " 'город',\n",
       " 'минимальный',\n",
       " 'угроза',\n",
       " 'максимальный',\n",
       " 'скорость',\n",
       " 'восстановление',\n",
       " 'исправление',\n",
       " 'ошибок.',\n",
       " 'преберечь',\n",
       " '«вирусную»',\n",
       " 'кампания',\n",
       " 'наращивание',\n",
       " 'запас',\n",
       " 'потом.<br>',\n",
       " '<br>',\n",
       " '<h3>сосредоточиться',\n",
       " 'сбор',\n",
       " 'отзыв',\n",
       " 'клиентов</h3><br>',\n",
       " 'уделить',\n",
       " 'особый',\n",
       " 'внимание',\n",
       " 'один',\n",
       " 'клиентам,',\n",
       " 'попросить',\n",
       " 'опубликовать',\n",
       " 'свой',\n",
       " 'отзыв',\n",
       " 'ваш',\n",
       " 'поддержку.',\n",
       " 'мочь',\n",
       " 'получить',\n",
       " 'поддержку,',\n",
       " 'ваш',\n",
       " 'личный',\n",
       " 'усилиями,',\n",
       " 'это',\n",
       " 'тревожный',\n",
       " 'сигнал,',\n",
       " 'свидетельствующий',\n",
       " 'том,',\n",
       " 'бизнес',\n",
       " 'испытывать',\n",
       " 'проблемы.<br>',\n",
       " '<br>',\n",
       " '<h3>участие',\n",
       " 'национальный',\n",
       " 'отраслевой',\n",
       " 'выставках</h3><br>',\n",
       " 'положительный',\n",
       " 'известность,',\n",
       " 'репутация',\n",
       " 'обратный',\n",
       " 'связь',\n",
       " 'окончательно',\n",
       " 'проверить',\n",
       " 'бизнес-модель',\n",
       " 'прототип',\n",
       " 'продукта.',\n",
       " 'участие',\n",
       " 'экспозиционный',\n",
       " 'мероприятие',\n",
       " 'стать',\n",
       " 'отличный',\n",
       " 'источник',\n",
       " 'налаживание',\n",
       " 'необходимый',\n",
       " 'связь',\n",
       " 'подготовка',\n",
       " 'масштабирование',\n",
       " 'бизнеса.<br>',\n",
       " '<br>',\n",
       " 'ваш',\n",
       " 'бизнес-модель',\n",
       " 'хороший',\n",
       " 'устойчивый',\n",
       " 'конкурентный',\n",
       " 'преимуществом,',\n",
       " 'продукт.',\n",
       " 'слишком',\n",
       " 'многие',\n",
       " 'бизнес-план',\n",
       " 'сосредоточить',\n",
       " 'продукт',\n",
       " 'упускать',\n",
       " 'другой',\n",
       " 'деталь',\n",
       " 'бизнес-модели.<br>',\n",
       " '<br>',\n",
       " 'приложение',\n",
       " 'усилие',\n",
       " 'разработка',\n",
       " 'продукта,',\n",
       " 'игнорирование',\n",
       " 'работа',\n",
       " 'бизнес-модель',\n",
       " 'характеризовать',\n",
       " 'выполнение',\n",
       " 'один',\n",
       " 'половина',\n",
       " 'подготовка',\n",
       " 'реальный',\n",
       " 'мир',\n",
       " 'бизнеса.',\n",
       " 'трудно',\n",
       " 'выиграть,',\n",
       " 'делать',\n",
       " 'полдела,',\n",
       " 'особенно',\n",
       " 'это',\n",
       " 'самый',\n",
       " 'простой',\n",
       " 'половина.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_clear'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = 300\n",
    "word2vec_model = word2vec.Word2Vec(data['content_clear'], size=dim_size, window=10, workers=8)\n",
    "\n",
    "w2v = dict(zip(word2vec_model.wv.index2word, word2vec_model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer', 0.8404650092124939),\n",
       " ('engineering', 0.8337506651878357),\n",
       " ('analysis', 0.8262729048728943),\n",
       " ('knowledge', 0.8219612240791321),\n",
       " ('learning', 0.8161517977714539),\n",
       " ('intelligence', 0.8151358962059021),\n",
       " ('artificial', 0.806818425655365),\n",
       " ('computational', 0.8048728108406067),\n",
       " ('science,', 0.8027878999710083),\n",
       " ('solutions', 0.8009922504425049)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(positive=['open', 'data', 'science', 'best'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30981, 300)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = mean_vectorizer(w2v).fit(data['content_clear']).transform(data['content_clear'])\n",
    "data_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23425, 300), (7556, 300), 3.4046228249071526, 3.304679829935242)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(train, y, ratio):\n",
    "    idx = ratio\n",
    "    return train[:idx, :], train[idx:, :], y[:idx], y[idx:]\n",
    "\n",
    "y = data['favs_lognorm']\n",
    "X_train, X_val, y_train, y_val = split(data_mean, y, 23425)\n",
    "X_train.shape, X_val.shape, np.mean(y_train), np.mean(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error:  0.9713214136821583\n",
      "Validation error:  0.8587660188788371\n",
      "Median prediction validation error:  1.4460163851213332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=1, random_state=17)\n",
    "model.fit(X_train, y_train)\n",
    "preds_train = model.predict(X_train)\n",
    "preds_val = model.predict(X_val)\n",
    "y_med = np.ones(len(preds_val)) * y_train.median()\n",
    "print('Train error: ', mean_squared_error(y_train, preds_train))\n",
    "print('Validation error: ', mean_squared_error(y_val, preds_val))\n",
    "print('Median prediction validation error: ', mean_squared_error(y_val, y_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23425 samples, validate on 7556 samples\n",
      "Epoch 1/28\n",
      " - 1s - loss: 3.3646 - val_loss: 1.4830\n",
      "Epoch 2/28\n",
      " - 1s - loss: 2.1676 - val_loss: 1.3921\n",
      "Epoch 3/28\n",
      " - 1s - loss: 2.0442 - val_loss: 1.3426\n",
      "Epoch 4/28\n",
      " - 1s - loss: 1.9593 - val_loss: 1.3141\n",
      "Epoch 5/28\n",
      " - 1s - loss: 1.8797 - val_loss: 1.2595\n",
      "Epoch 6/28\n",
      " - 1s - loss: 1.8077 - val_loss: 1.2041\n",
      "Epoch 7/28\n",
      " - 1s - loss: 1.7365 - val_loss: 1.1633\n",
      "Epoch 8/28\n",
      " - 1s - loss: 1.7086 - val_loss: 1.1278\n",
      "Epoch 9/28\n",
      " - 1s - loss: 1.6342 - val_loss: 1.1158\n",
      "Epoch 10/28\n",
      " - 1s - loss: 1.5896 - val_loss: 1.0635\n",
      "Epoch 11/28\n",
      " - 1s - loss: 1.5650 - val_loss: 1.0217\n",
      "Epoch 12/28\n",
      " - 1s - loss: 1.5044 - val_loss: 1.0025\n",
      "Epoch 13/28\n",
      " - 1s - loss: 1.4723 - val_loss: 0.9855\n",
      "Epoch 14/28\n",
      " - 1s - loss: 1.4663 - val_loss: 0.9530\n",
      "Epoch 15/28\n",
      " - 1s - loss: 1.4040 - val_loss: 0.9382\n",
      "Epoch 16/28\n",
      " - 1s - loss: 1.3730 - val_loss: 0.9183\n",
      "Epoch 17/28\n",
      " - 1s - loss: 1.3501 - val_loss: 0.8987\n",
      "Epoch 18/28\n",
      " - 1s - loss: 1.3050 - val_loss: 0.8773\n",
      "Epoch 19/28\n",
      " - 1s - loss: 1.2986 - val_loss: 0.8824\n",
      "Epoch 20/28\n",
      " - 1s - loss: 1.2731 - val_loss: 0.8571\n",
      "Epoch 21/28\n",
      " - 1s - loss: 1.2499 - val_loss: 0.8513\n",
      "Epoch 22/28\n",
      " - 1s - loss: 1.2324 - val_loss: 0.8486\n",
      "Epoch 23/28\n",
      " - 1s - loss: 1.2092 - val_loss: 0.8231\n",
      "Epoch 24/28\n",
      " - 1s - loss: 1.2118 - val_loss: 0.8265\n",
      "Epoch 25/28\n",
      " - 1s - loss: 1.1886 - val_loss: 0.8280\n",
      "Epoch 26/28\n",
      " - 1s - loss: 1.1865 - val_loss: 0.8034\n",
      "Epoch 27/28\n",
      " - 1s - loss: 1.1560 - val_loss: 0.8413\n",
      "Epoch 28/28\n",
      " - 1s - loss: 1.1544 - val_loss: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6cb2f8400>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    #optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#     optimizer = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, \n",
    "                           epochs=28, nb_epoch=7, batch_size=64,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           verbose=2)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "class tfidf_vectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(next(iter(self.word2vec.values())))\n",
    "        \n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x:x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "#         print('max_idf: ', max_idf)\n",
    "        self.word2weight = dict(zip(vectorizer.get_feature_names(), tfidf.idf_))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec.get(w, np.zeros(self.dim)) * self.word2weight.get(w, np.zeros(self.dim)) \n",
    "                    for w in words], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_idf:  10.648014489106362\n"
     ]
    }
   ],
   "source": [
    "data_mean_tfidf = tfidf_vectorizer(w2v).fit(data['content_clear']).transform(data['content_clear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_mean_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23425, 300), (7556, 300), 3.4046228249071526, 3.304679829935242)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(train, y, ratio):\n",
    "    idx = ratio\n",
    "    return train[:idx, :], train[idx:, :], y[:idx], y[idx:]\n",
    "\n",
    "y = data['favs_lognorm']\n",
    "X_train, X_val, y_train, y_val = split(data_mean_tfidf, y, 23425)\n",
    "X_train.shape, X_val.shape, np.mean(y_train), np.mean(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error:  0.9713214136821583\n",
      "Validation error:  0.8587660188788371\n",
      "Median prediction validation error:  1.4460163851213332\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=1, random_state=17)\n",
    "model.fit(X_train, y_train)\n",
    "preds_train = model.predict(X_train)\n",
    "preds_val = model.predict(X_val)\n",
    "y_med = np.ones(len(preds_val)) * y_train.median()\n",
    "print('Train error: ', mean_squared_error(y_train, preds_train))\n",
    "print('Validation error: ', mean_squared_error(y_val, preds_val))\n",
    "print('Median prediction validation error: ', mean_squared_error(y_val, y_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23425 samples, validate on 7556 samples\n",
      "Epoch 1/28\n",
      " - 1s - loss: 3.6244 - val_loss: 1.4975\n",
      "Epoch 2/28\n",
      " - 1s - loss: 2.2653 - val_loss: 1.3919\n",
      "Epoch 3/28\n",
      " - 1s - loss: 2.1148 - val_loss: 1.3471\n",
      "Epoch 4/28\n",
      " - 1s - loss: 2.0057 - val_loss: 1.3201\n",
      "Epoch 5/28\n",
      " - 1s - loss: 1.9548 - val_loss: 1.2585\n",
      "Epoch 6/28\n",
      " - 1s - loss: 1.9048 - val_loss: 1.2525\n",
      "Epoch 7/28\n",
      " - 1s - loss: 1.8718 - val_loss: 1.1932\n",
      "Epoch 8/28\n",
      " - 1s - loss: 1.7992 - val_loss: 1.1587\n",
      "Epoch 9/28\n",
      " - 1s - loss: 1.7700 - val_loss: 1.1469\n",
      "Epoch 10/28\n",
      " - 1s - loss: 1.7196 - val_loss: 1.0822\n",
      "Epoch 11/28\n",
      " - 1s - loss: 1.6603 - val_loss: 1.0545\n",
      "Epoch 12/28\n",
      " - 1s - loss: 1.6332 - val_loss: 1.0481\n",
      "Epoch 13/28\n",
      " - 1s - loss: 1.5757 - val_loss: 0.9993\n",
      "Epoch 14/28\n",
      " - 1s - loss: 1.5453 - val_loss: 0.9699\n",
      "Epoch 15/28\n",
      " - 1s - loss: 1.5050 - val_loss: 0.9520\n",
      "Epoch 16/28\n",
      " - 1s - loss: 1.4557 - val_loss: 0.9278\n",
      "Epoch 17/28\n",
      " - 1s - loss: 1.4428 - val_loss: 0.9109\n",
      "Epoch 18/28\n",
      " - 1s - loss: 1.4038 - val_loss: 0.9219\n",
      "Epoch 19/28\n",
      " - 1s - loss: 1.4029 - val_loss: 0.9269\n",
      "Epoch 20/28\n",
      " - 1s - loss: 1.3652 - val_loss: 0.8615\n",
      "Epoch 21/28\n",
      " - 1s - loss: 1.3304 - val_loss: 0.8754\n",
      "Epoch 22/28\n",
      " - 1s - loss: 1.3253 - val_loss: 0.9081\n",
      "Epoch 23/28\n",
      " - 1s - loss: 1.2949 - val_loss: 0.8335\n",
      "Epoch 24/28\n",
      " - 1s - loss: 1.2749 - val_loss: 0.8140\n",
      "Epoch 25/28\n",
      " - 1s - loss: 1.2643 - val_loss: 0.8092\n",
      "Epoch 26/28\n",
      " - 1s - loss: 1.2489 - val_loss: 0.8211\n",
      "Epoch 27/28\n",
      " - 1s - loss: 1.2339 - val_loss: 0.7990\n",
      "Epoch 28/28\n",
      " - 1s - loss: 1.2185 - val_loss: 0.7955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6cbd2a518>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    #optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#     optimizer = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, \n",
    "                           epochs=28, nb_epoch=7, batch_size=64,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           verbose=2)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train, label=y_train, missing=np.nan)\n",
    "d_val = xgb.DMatrix(X_val, label=y_val, missing=np.nan)\n",
    "watchlist = [(d_train, 'train'), (d_val, 'test')]\n",
    "history = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 26,\n",
    "    'eta': 0.025,\n",
    "    'nthread': 8,\n",
    "    'gamma' : 1,\n",
    "    'lambda' : 1,\n",
    "    'subsample': 0.85,\n",
    "    'eval_metric': ['rmse'],\n",
    "    'objective': 'reg:linear',\n",
    "    'colsample_bytree': 0.9,\n",
    "    'min_child_weight': 100,\n",
    "    'scale_pos_weight':(1)/y.mean(),\n",
    "    'seed':7,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.19147\ttest-rmse:3.05002\n",
      "[20]\ttrain-rmse:3.17675\ttest-rmse:3.0357\n",
      "[40]\ttrain-rmse:3.16235\ttest-rmse:3.02194\n",
      "[60]\ttrain-rmse:3.15544\ttest-rmse:3.01584\n",
      "[80]\ttrain-rmse:3.14742\ttest-rmse:3.0083\n",
      "[100]\ttrain-rmse:3.14385\ttest-rmse:3.00517\n",
      "[120]\ttrain-rmse:3.13858\ttest-rmse:3.00036\n",
      "[140]\ttrain-rmse:3.13741\ttest-rmse:2.99952\n",
      "[160]\ttrain-rmse:3.13322\ttest-rmse:2.99545\n",
      "[180]\ttrain-rmse:3.1317\ttest-rmse:2.99403\n",
      "[199]\ttrain-rmse:3.13188\ttest-rmse:2.99431\n"
     ]
    }
   ],
   "source": [
    "model_new = xgb.train(params,\n",
    "                     d_train,\n",
    "                     num_boost_round=200,\n",
    "                     evals=watchlist,\n",
    "                     evals_result=history,\n",
    "                     verbose_eval=20,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
